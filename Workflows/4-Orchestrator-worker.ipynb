{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Orchestrator-Worker WorkFlow\n",
    "\n",
    "In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs and synthesizes their results\n",
    "\n",
    "When to use this workflow: This workflow is well-suited for complex tasks where you can't predict the subtasks need (in coding, for e.g. the number of files that need to be changed and the nature of the change in each file likely depend on the task).  Whereas it's topographically similar, the key different from parallelization is its flexibility - subtasks aren't pre-defined, but determined by the orchestrator based on the specific input."
   ],
   "id": "a2e070780ca89e85"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-04T16:32:15.800676Z",
     "start_time": "2025-11-04T16:32:15.788680Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T16:32:17.006980Z",
     "start_time": "2025-11-04T16:32:15.805271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\")"
   ],
   "id": "fcf151cd97646b87",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T16:32:17.026014Z",
     "start_time": "2025-11-04T16:32:17.020294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated, List, TypedDict\n",
    "import operator\n",
    "from typing_extensions import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ],
   "id": "1249a48d7f6888e2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T16:32:17.054762Z",
     "start_time": "2025-11-04T16:32:17.042162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Schema for structured output to use in planning\n",
    "class Section(BaseModel):\n",
    "    title: str  = Field(description=\"Title for this section of the report\")\n",
    "    description: str = Field(description=\"Brief Overview of the main topics and concepts of the section\")\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(description=\"Sections of the report\")\n",
    "\n",
    "planner = llm.with_structured_output(Sections)"
   ],
   "id": "69c1ade1e9a0693f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating workers dynamically in LangGraph\n",
    "\n",
    "Because orchestrator-worker workflows are common, LangGraph has the send API to support this. It lets you dynamically create worker nodes and send one a specific input. Each worker has its own state, and all worker outputs are written to a shared state key that is accessible to orchestrator graph. this gives the orchestrator access to all worker output and allows it to synthesize them into a final output. As you can see below, we iterate over a list of sections and Send each to a worker node."
   ],
   "id": "66bcdee40be8ff8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T16:32:17.101959Z",
     "start_time": "2025-11-04T16:32:17.058480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.types import Send\n",
    "\n",
    "# common state\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    sections : list[Section]\n",
    "    completed_sections: Annotated[list, operator.add]\n",
    "    final_report :str\n",
    "\n",
    "# worker state\n",
    "class WorkerState(TypedDict):\n",
    "    section: Section\n",
    "    completed_sections: Annotated[list, operator.add]\n"
   ],
   "id": "3fca672aa8824cbb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T16:32:17.111203Z",
     "start_time": "2025-11-04T16:32:17.106570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define nodes\n",
    "def orchestrator(state: State):\n",
    "    \"\"\" Orchestrator that generates a plan for the report \"\"\"\n",
    "\n",
    "    # Generate queries\n",
    "    report_sections = planner.invoke(\n",
    "            [\n",
    "                    SystemMessage(content=\"Generate a plan for the report.\"),\n",
    "                    HumanMessage(content=f\"Here is the report topic: {state[\"topic\"]}\")\n",
    "            ]\n",
    "    )\n",
    "    # print(f\"Report sections: {report_sections}\")\n",
    "\n",
    "    return {\"sections\": report_sections.sections}"
   ],
   "id": "bd4db8525ef0327",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T16:32:17.125208Z",
     "start_time": "2025-11-04T16:32:17.120221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def llm_call(state: WorkerState):\n",
    "    \"\"\" Worker writes a section of the repor t\"\"\"\n",
    "\n",
    "    # Generate a section\n",
    "    section = llm.invoke(\n",
    "            [\n",
    "                    SystemMessage(content=\"Write a report section following the provided name and description. Include no preamble for each section and use markdown formatting\"),\n",
    "                    HumanMessage(content=f\"Here is the section name: {state[\"section\"].title} and description: {state['section'].description}\")\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    return {\"completed_sections\": [section.content]}"
   ],
   "id": "5d86728b00b55b6f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T16:32:17.155191Z",
     "start_time": "2025-11-04T16:32:17.149484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# conditional edge function to create llm_call workers that each write a section of the report.\n",
    "def assign_workers(state: State):\n",
    "    \"\"\" Assign a worker to each section of the plan\"\"\"\n",
    "\n",
    "    # kick off section writing parallel via Send() API\n",
    "    return [Send(\"llm_call\", {\"section\" : s}) for s in state[\"sections\"]]"
   ],
   "id": "3fdd8e1a5917839d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T16:32:17.184894Z",
     "start_time": "2025-11-04T16:32:17.179244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def synthesizer(state: State):\n",
    "    \"\"\" Synthesiz the full report from sections \"\"\"\n",
    "\n",
    "    # list of completed sections\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "\n",
    "    # format completed section to str to use as context for final sections\n",
    "    completed_report_sections = \"\\n\\n------\\n\\n\".join(completed_sections)\n",
    "\n",
    "    return {\"final_report\": completed_report_sections}"
   ],
   "id": "1a1f97dced69244c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T16:32:17.274307Z",
     "start_time": "2025-11-04T16:32:17.211489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "builder = StateGraph(State) # type:ignore\n",
    "\n",
    "# add the nodes\n",
    "builder.add_node(\"orchestrator\", orchestrator)\n",
    "builder.add_node(\"llm_call\", llm_call)\n",
    "builder.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "# add edges\n",
    "builder.add_edge(START, \"orchestrator\")\n",
    "builder.add_conditional_edges(\"orchestrator\", assign_workers, [\"llm_call\"])\n",
    "builder.add_edge(\"llm_call\", \"synthesizer\")\n",
    "builder.add_edge(\"synthesizer\", END)"
   ],
   "id": "85f59c5e0905f17d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x113e6329280>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T16:32:17.621710Z",
     "start_time": "2025-11-04T16:32:17.278395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "graph =builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "c6d182c0957bf81e",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T16:34:24.407350Z",
     "start_time": "2025-11-04T16:34:22.365329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# invoke\n",
    "state = graph.invoke({\"topic\" : \"Create a report on Agentic AI RAGs\"})\n",
    "\n",
    "from IPython.display import Markdown\n",
    "Markdown(state[\"final_report\"])"
   ],
   "id": "d65827301190121c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Executive Summary\n\nAgentic AI Retrieval-Augmented Generation (RAG) combines the autonomy of advanced language models with precise, context‑sourced information retrieval to produce outputs that are both insightful and factually grounded. This report demonstrates that:\n\n- **Enhanced Accuracy**: RAG reduces hallucinations by up to 45 % compared to vanilla generative models, ensuring higher reliability in knowledge‑intensive applications.\n- **Scalable Knowledge Updates**: By decoupling the knowledge base from the model, organizations can refresh data in real time without retraining, cutting deployment cycles by 70 %.\n- **Improved User Trust**: Transparency mechanisms built into RAG’s retrieval pipeline increase user confidence, with a 32 % rise in satisfaction scores in pilot studies.\n- **Economic Efficiency**: Leveraging lightweight retrieval modules allows cost‑effective scaling on commodity hardware, lowering inference costs by 30 % relative to full‑model fine‑tuning.\n\nThese findings underscore RAG’s pivotal role in bridging the gap between powerful generative AI and dependable, up‑to‑date knowledge, positioning it as a cornerstone technology for next‑generation AI systems.\n\n------\n\n## Introduction to Agentic AI\n\nAgentic AI refers to artificial intelligence systems that possess **agency**—the capacity to set goals, plan actions, and adapt strategies autonomously in pursuit of those goals. Unlike conventional AI that follows pre‑programmed rules or static models, agentic AI integrates perception, reasoning, and learning to act as a self‑directed decision maker.\n\n### Distinguishing Features\n- **Goal‑oriented autonomy**: Agents formulate and revise objectives based on environmental feedback.  \n- **Strategic planning**: They construct multi‑step plans, evaluate trade‑offs, and select actions that maximize expected utility.  \n- **Learning & adaptation**: Continuous refinement of models through reinforcement learning, self‑play, or meta‑learning.  \n- **Self‑monitoring & introspection**: Agents assess their own performance, detect failures, and adjust behavior accordingly.  \n- **Interaction with humans and other agents**: Capable of negotiation, collaboration, and coordination in complex ecosystems.\n\n### Role in Advancing Autonomous Decision‑Making\n- **Scalable autonomy**: Enables deployment in dynamic domains (e.g., robotics, autonomous vehicles, smart grids) where fixed rules are insufficient.  \n- **Robustness to uncertainty**: Adaptive strategies allow agents to handle unforeseen events and partial observability.  \n- **Ethical alignment**: By embedding value learning and preference modeling, agentic AI can align decisions with human norms and policies.  \n- **Accelerated innovation**: Agentic systems can discover novel solutions and optimize processes faster than human‑driven approaches.  \n\nIn sum, Agentic AI transforms AI from reactive tools into proactive partners, driving progress toward truly autonomous, intelligent systems.\n\n------\n\n## Understanding Retrieval-Augmented Generation (RAG)\n\nRetrieval‑Augmented Generation (RAG) is a hybrid architecture that combines a **retriever**—which fetches relevant external documents or knowledge snippets—and a **generator**—typically a large language model (LLM)—which produces the final text conditioned on both the user query and the retrieved content. This synergy enables the system to produce more accurate, fact‑grounded, and contextually rich responses than a pure generative model.\n\n### Core Components\n\n| Component | Role | Typical Implementation |\n|-----------|------|------------------------|\n| **Retriever** | Scans a large corpus (e.g., Wikipedia, proprietary knowledge bases, or domain‑specific datasets) to identify passages most relevant to the input query. | Dense vector search (e.g., FAISS with sentence‑transformers), sparse BM25, or hybrid methods combining dense and lexical retrieval. |\n| **Generator** | Generates natural‑language output conditioned on the query and the retrieved passages. | Encoder‑decoder models like T5, BART, or GPT‑style transformers fine‑tuned on retrieval‑augmented training data. |\n| **Fusion Mechanism** | Merges retrieved evidence with the query to inform the generator. | Techniques include concatenation, cross‑attention, or dynamic prompting where retrieved text is injected into the prompt. |\n| **Re‑ranking / Feedback Loop** | Optional step to re‑order retrieved passages based on generation confidence or external scoring. | Learned re‑ranking models, heuristic scoring, or user feedback signals. |\n\n### How RAG Enhances Language Model Outputs\n\n1. **Fact‑Grounded Responses**  \n   By conditioning on actual documents, the generator can cite specific facts, reducing hallucinations and increasing factual correctness.\n\n2. **Expanded Knowledge Base**  \n   The retriever can access an arbitrarily large corpus, effectively extending the model’s knowledge beyond its fixed training data.\n\n3. **Dynamic Context Adaptation**  \n   For domain‑specific queries, the system can retrieve specialized documents, allowing the generator to adapt its style and terminology accordingly.\n\n4. **Efficient Fine‑Tuning**  \n   Instead of retraining a massive LLM on all domain data, only the retriever and a lightweight generator head need to be fine‑tuned, saving compute and storage.\n\n5. **Explainability**  \n   The retrieved passages serve as explicit evidence for the generated answer, enabling audit trails and easier debugging.\n\n### Typical Workflow\n\n1. **Input** – User submits a query.  \n2. **Retrieval** – The retriever encodes the query, searches the indexed corpus, and returns top‑k passages.  \n3. **Fusion** – The generator receives the query and retrieved passages (often concatenated or fed into cross‑attention).  \n4. **Generation** – The generator produces the final answer, optionally with citations or confidence scores.  \n5. **Post‑processing** – Optional re‑ranking, formatting, or user‑feedback integration.\n\n### Key Takeaways\n\n- RAG marries the **breadth** of large language models with the **depth** of external knowledge sources.  \n- The retriever provides up‑to‑date, domain‑specific evidence that the generator can directly reference.  \n- This framework reduces hallucinations, improves factuality, and makes LLMs more adaptable to specialized tasks.\n\n------\n\n## Combining Agentic AI with RAG\n\nAgentic AI systems—those that can plan, decide, and act autonomously—gain a powerful edge when paired with Retrieval-Augmented Generation (RAG). By embedding a retrieval module into an agent’s decision loop, the agent can dynamically query external knowledge bases, refine its internal plan, and produce more accurate, context‑aware outputs. This synergy unfolds across several dimensions:\n\n### 1. Autonomous Retrieval as a Decision Primitive  \nRather than treating retrieval as a static pre‑processing step, an agent can treat “retrieve” as an action in its action space. For example, a customer‑support agent may decide to *search* a product manual before responding. The agent evaluates the current state, predicts that the existing knowledge base is insufficient, and triggers a retrieval query. This decision is informed by confidence scores, policy gradients, or reinforcement signals that reward successful completions.\n\n### 2. Continuous Knowledge Refresh  \nAgentic systems can continuously monitor knowledge drift or updates in external sources. By periodically querying for new documents, the agent keeps its internal model aligned with the latest facts. This is especially valuable in domains such as finance or healthcare, where regulations and best practices evolve rapidly.\n\n### 3. Multi‑Step Retrieval & Reasoning Loops  \nRAG’s generative backbone can be extended into a multi‑step loop:  \n1. **Plan** – the agent outlines a strategy (e.g., “first find the policy, then summarize it”).  \n2. **Retrieve** – fetch documents relevant to the sub‑goal.  \n3. **Generate** – produce a partial answer or next action.  \n4. **Evaluate** – assess whether the partial answer satisfies the goal; if not, loop back.  \n\nThis iterative loop mirrors human problem‑solving, allowing the agent to refine its reasoning with fresh evidence at each cycle.\n\n### 4. Context‑Aware Retrieval Filters  \nAgents can learn retrieval filters that adapt to the conversation context. For instance, a medical triage bot might prioritize peer‑reviewed journals over lay articles when the user reports severe symptoms. The policy can be trained to weigh source credibility, recency, and relevance simultaneously.\n\n### 5. Explainability and Provenance  \nBecause each generated response can be traced back to the retrieved documents, agents provide transparent provenance. This is crucial for compliance and auditability, especially in regulated industries. Agents can also generate meta‑explanations: “I retrieved article X because it mentions the exact symptom Y,” giving users insight into the reasoning path.\n\n### 6. Efficiency via Retrieval‑First Planning  \nBy retrieving relevant snippets before full generation, agents reduce hallucination risk and computational load. The language model focuses on synthesis rather than searching, leading to faster inference and lower token usage—a significant advantage for cost‑sensitive deployments.\n\n### 7. Learning from Retrieval Outcomes  \nAgents can incorporate feedback on retrieval quality into their learning loop. If a retrieved document fails to improve the answer, the agent can adjust its retrieval embeddings or query formulation. Over time, the agent learns to ask more precise questions, improving overall performance.\n\n---\n\n### Practical Implementation Blueprint\n\n| Component | Role | Example |\n|-----------|------|---------|\n| **Policy Network** | Decides when to retrieve or act | RL‑trained policy that selects `RETRIEVE` vs. `GENERATE` |\n| **Retrieval Engine** | Executes vector‑search or keyword query | Pinecone, ElasticSearch, or a custom FAISS index |\n| **Memory Buffer** | Stores retrieved docs and past interactions | Short‑term episodic memory for context |\n| **Reasoning Layer** | Generates answer conditioned on retrieved docs | Transformer decoder with RAG architecture |\n| **Evaluation Module** | Scores answer quality and informs policy | BLEU, ROUGE, or task‑specific metrics |\n\nBy weaving these components together, an agent can autonomously navigate vast knowledge bases, reason in real time, and produce high‑fidelity, contextually grounded responses. The resulting system embodies a true blend of *agency* and *augmented intelligence*, pushing the frontier of what autonomous AI can achieve.\n\n------\n\n# Architectural Overview\n\n- **Data Ingestion Layer**  \n  - Real‑time streams from sensors, logs, and external APIs are captured via Kafka topics.  \n  - Batch files (e.g., nightly logs, nightly backups) are ingested through Spark Structured Streaming and stored in a data lake (S3/ADLS).  \n  - A schema registry ensures consistent data contracts across producers and consumers.\n\n- **ETL / Data Pipeline**  \n  - Spark/Databricks notebooks transform raw events into canonical fact tables and dimension models.  \n  - Incremental processing updates the data lake and feeds downstream analytics services.  \n  - Data quality checks (deduplication, range validation) are enforced via automated tests and alerting.\n\n- **Knowledge Base Layer**  \n  - A graph database (Neo4j/JanusGraph) stores domain entities, relationships, and metadata, enabling semantic queries.  \n  - A vector store (FAISS/Pinecone) indexes embeddings generated by LLMs for retrieval‑augmented inference.  \n  - A knowledge graph ontology defines business rules and inference patterns that the agents can query.\n\n- **Agent Control Loop**  \n  - **Orchestration Engine** (e.g., Temporal, Airflow) schedules agent tasks, manages retries, and maintains state.  \n  - **Agent Runtime** executes LLM-driven logic, interacting with the knowledge base and external APIs.  \n  - **Feedback Loop** captures agent outputs, logs them, and feeds them back into the data lake for continuous learning and auditability.\n\n- **Observability & Governance**  \n  - Centralized logging (ELK/Graylog) and metrics (Prometheus/Grafana) monitor pipeline health.  \n  - Data catalog (DataHub/Amundsen) provides lineage, schema, and access control.  \n  - Security policies enforce role‑based access to data and model endpoints.\n\nThis architecture ensures scalable ingestion, robust knowledge representation, and autonomous agent execution, all governed by observability and compliance controls.\n\n------\n\n## Key Algorithms and Techniques\n\n### Retrieval\n| Algorithm | Core Idea | Typical Use‑Case |\n|-----------|-----------|------------------|\n| **Vector Search (ANN)** | Approximate nearest neighbor search on high‑dimensional embeddings. | Fast similarity search in large embedding collections. |\n| **Hierarchical Navigable Small World (HNSW)** | Graph‑based ANN with logarithmic search complexity. | Production‑grade retrieval in services like Pinecone, Milvus. |\n| **FAISS / Annoy** | Library‑level implementations of multiple ANN strategies. | Benchmarking and prototyping of retrieval pipelines. |\n| **Semantic Indexing** | Combine dense embeddings with sparse lexical indices (e.g., BM25) for hybrid retrieval. | Improving recall while retaining speed. |\n| **Sparse‑Dense Fusion** | Weighted combination of BM25 scores and embedding similarity. | Search in legal, medical, and scholarly domains. |\n\n### Generation\n| Technique | Core Idea | Typical Use‑Case |\n|-----------|-----------|------------------|\n| **Prompt Engineering** | Crafting prompt templates, instruction tuning, chain‑of‑thought prompting. | Enhancing LLM accuracy on reasoning tasks. |\n| **Few‑Shot Prompting** | Providing a handful of exemplars to steer model behavior. | Rapid domain adaptation without fine‑tuning. |\n| **Fine‑Tuning (Supervised)** | Updating model weights on domain‑specific corpora. | Custom LLMs for finance, healthcare, or legal text. |\n| **Low‑Rank Adaptation (LoRA)** | Adding trainable rank‑deficient matrices to frozen LLM weights. | Efficient fine‑tuning with minimal memory. |\n| **Reinforcement Learning from Human Feedback (RLHF)** | Optimizing policy via reward models trained on human preferences. | Aligning LLM outputs with user intent and safety. |\n| **Prompt‑to‑Prompt Transfer** | Using a model to generate new prompts for downstream tasks. | Meta‑learning and continual adaptation. |\n\n### Agent Planning\n| Approach | Core Idea | Typical Use‑Case |\n|----------|-----------|------------------|\n| **Hierarchical Planning** | Decompose long‑term goals into sub‑goals, each solved by a sub‑planner. | Complex workflows in logistics or software deployment. |\n| **Reinforcement Learning (RL)** | Learn policy via interaction with environment, maximizing cumulative reward. | Autonomous navigation, dialogue management. |\n| **Monte Carlo Tree Search (MCTS)** | Explore action sequences via simulated rollouts; useful with deterministic or partially observable environments. | Game‑playing agents, combinatorial optimization. |\n| **LLM‑Based Planner** | Use the LLM itself to generate action plans (e.g., via “plan‑then‑act” prompting). | Rapid prototyping of task sequences when formal models are unavailable. |\n| **Hybrid Planner** | Combine symbolic planners (e.g., PDDL) with neural components for perception and action selection. | Robotics, autonomous driving, and industrial automation. |\n\n---\n\nThese algorithms form the backbone of modern retrieval‑augmented generation (RAG) pipelines, large‑language‑model (LLM) based agents, and advanced planning systems. Selecting the right mix depends on data scale, latency requirements, domain specificity, and safety constraints.\n\n------\n\n## Applications and Use Cases\n\n- **Customer Support Bots**  \n  - *24/7 Availability*: AI agents handle routine inquiries, freeing human agents for complex issues.  \n  - *Multilingual Support*: Real‑time translation allows companies to serve global customers without language barriers.  \n  - *Personalized Interaction*: By analyzing past interactions and purchase history, bots can recommend products or solutions tailored to each user.\n\n- **Research Assistants**  \n  - *Literature Review*: Automated summarization of large corpora of academic papers speeds up hypothesis generation.  \n  - *Data Extraction*: Structured extraction of experimental details (methods, results, metrics) from PDFs or lab notebooks.  \n  - *Hypothesis Generation*: Suggesting potential research directions based on gaps identified in existing literature.\n\n- **Content Creation**  \n  - *Drafting and Editing*: AI‑generated outlines, first drafts, or style‑enhanced revisions for blogs, white papers, and social media posts.  \n  - *Multimedia Integration*: Generating captions, transcripts, or even basic visual assets that complement written content.  \n  - *Localization*: Automatic translation and cultural adaptation of content for diverse markets.\n\n- **Decision Support Systems**  \n  - *Business Intelligence*: Synthesizing reports from disparate data sources to highlight key trends and anomalies.  \n  - *Risk Assessment*: Predictive models that evaluate potential risks in finance, supply chain, or healthcare.  \n  - *Strategic Planning*: Scenario simulation tools that explore the impact of different decisions on organizational KPIs.\n\n------\n\n## Challenges and Limitations\n\n### Technical Challenges\n- **Hallucination**: The model can generate plausible but factually incorrect or nonsensical statements, especially when prompted with ambiguous or incomplete information.\n- **Contextual Drift**: Difficulty maintaining coherence over long conversations or documents, leading to inconsistent or contradictory responses.\n- **Generalization Limits**: Performance drops on niche or rapidly evolving domains where training data is sparse or outdated.\n- **Robustness to Adversarial Input**: Vulnerable to prompts designed to elicit disallowed content or to bypass safety filters.\n\n### Ethical Challenges\n- **Bias and Fairness**: Systematic biases inherited from training corpora can manifest in gender, racial, or cultural stereotypes, affecting the fairness of outputs.\n- **Representation Gaps**: Underrepresentation of minority voices leads to skewed knowledge and potential marginalization of certain perspectives.\n- **Misinformation Amplification**: The model’s tendency to produce confident-sounding but incorrect facts can contribute to the spread of misinformation.\n- **Transparency and Explainability**: Difficulty in interpreting why a particular answer was generated hampers accountability and user trust.\n\n### Safety Challenges\n- **Misuse Potential**: The ability to generate persuasive or deceptive text raises concerns about phishing, fraud, or political manipulation.\n- **Disallowed Content**: Despite filtering, the model may still produce or facilitate content that violates policy, such as hate speech or instructions for wrongdoing.\n- **Adversarial Exploitation**: Attackers can craft prompts to force the model into revealing sensitive or proprietary information.\n\n### Data Privacy Challenges\n- **Training Data Leakage**: Exposure of personal or proprietary information inadvertently present in training datasets can lead to privacy violations.\n- **User Data Handling**: Ensuring that user interactions are not stored or used for downstream training without explicit consent.\n- **Regulatory Compliance**: Navigating GDPR, CCPA, and other jurisdictional privacy laws while maintaining model effectiveness.\n\n### Resource Constraints\n- **Compute Costs**: Training large language models requires massive GPU/TPU resources, leading to high energy consumption and carbon footprint.\n- **Inference Latency**: Real‑time applications demand low latency, which can conflict with the computational demands of complex models.\n- **Model Size vs. Deployment**: Balancing the trade‑off between a highly capable model and the feasibility of deploying it on edge devices or in bandwidth‑constrained environments.\n\n------\n\n## Evaluation Metrics and Benchmarks\n\n| **Aspect** | **Metric** | **Definition / Formula** | **Typical Benchmark / Reference** |\n|------------|------------|---------------------------|------------------------------------|\n| **Retrieval Accuracy** | **Precision@k** | \\( \\frac{\\text{Relevant retrieved at }k}{k} \\) | MS‑MARCO passage ranking, TREC Web 2023 |\n| | **Recall@k** | \\( \\frac{\\text{Relevant retrieved at }k}{\\text{Total relevant}} \\) | MS‑MARCO passage ranking |\n| | **Mean Reciprocal Rank (MRR)** | \\( \\frac{1}{|Q|}\\sum_{i=1}^{|Q|}\\frac{1}{rank_i} \\) | TREC QA, MS‑MARCO passage ranking |\n| | **Mean Average Precision (MAP)** | Average of precision values at each relevant hit | TREC Web, MS‑MARCO |\n| | **Normalized Discounted Cumulative Gain (NDCG)** | \\( \\frac{DCG}{IDCG} \\) where \\( DCG = \\sum_{i=1}^{k}\\frac{2^{rel_i}-1}{\\log_2(i+1)} \\) | TREC Web, MS‑MARCO |\n| | **Recall@10/50/100** | Fraction of queries with at least one relevant document in top‑k | TREC Web, MS‑MARCO |\n| **Generation Quality** | **BLEU** | n‑gram overlap with references | WMT, MS‑MARCO passage ranking |\n| | **ROUGE‑L** | Longest common subsequence based recall | Summarization benchmarks |\n| | **METEOR** | Alignment‑based metric with synonymy | WMT, MS‑MARCO |\n| | **BERTScore** | Cosine similarity of contextual embeddings | General NLG benchmarks |\n| | **Human Fluency & Adequacy** | Likert‑scale rating by annotators | NLG Challenge, SQuAD v2.0 |\n| | **Faithfulness (e.g., FactCC, QAGS)** | Proportion of statements that are entailed by source | Fact verification datasets |\n| **Agent Autonomy** | **Task Completion Rate** | \\( \\frac{\\text{Tasks finished successfully}}{\\text{Total tasks}} \\) | Simulated dialogue tasks |\n| | **Plan Adherence** | Fraction of plan steps executed as intended | Autonomous navigation benchmarks |\n| | **Self‑Correction Rate** | Number of corrections made by agent / total actions | Interactive QA systems |\n| | **Exploration vs Exploitation Balance** | Entropy of action distribution | Reinforcement learning benchmarks |\n| | **Goal‑Achievement Score** | Binary or graded success per sub‑goal | Multi‑step reasoning datasets |\n| **Overall System Performance** | **Latency** | Avg. time from request to response | End‑to‑end QA latency |\n| | **Throughput** | Queries processed per second | Load‑testing suites |\n| | **Resource Utilization** | CPU, GPU, memory usage | Cloud cost metrics |\n| | **Cost per Query** | Monetary cost / # queries | Cloud pricing APIs |\n| | **Robustness** | Failure rate under adversarial inputs | Robustness benchmarks (e.g., AdversarialQA) |\n| | **Scalability** | Performance trend as user load increases | Stress‑test results |\n\n### Benchmarking Procedures\n\n1. **Dataset Selection**  \n   - *Retrieval*: MS‑MARCO passage ranking, TREC Web, Natural Questions.  \n   - *Generation*: WMT, MS‑MARCO passage ranking, SummEval.  \n   - *Autonomy*: Multi‑step reasoning datasets (e.g., Multi‑Hop QA), simulated dialogue logs.  \n   - *System Performance*: Synthetic load generators (e.g., Apache JMeter, Locust).\n\n2. **Metric Aggregation**  \n   - Report both **average** and **distribution** (e.g., 95th percentile latency).  \n   - Use **confidence intervals** (e.g., 95% CI) for statistical significance.\n\n3. **Human Evaluation**  \n   - For generation and autonomy, employ **double‑blind** annotator protocols.  \n   - Use **inter‑annotator agreement** (Krippendorff’s α) to validate consistency.\n\n4. **Continuous Monitoring**  \n   - Implement dashboards (Grafana, Kibana) for real‑time tracking of latency, throughput, and failure rates.  \n   - Trigger alerts when metrics deviate beyond predefined thresholds.\n\n5. **Benchmark Reporting**  \n   - Publish **leaderboards** per metric to foster community comparison.  \n   - Include **ablation studies** to isolate contributions of retrieval, generation, and autonomy modules.\n\nBy systematically applying these metrics and benchmarks, the system’s retrieval precision, generative coherence, agent autonomy, and overall operational health can be rigorously quantified and compared against state‑of‑the‑art baselines.\n\n------\n\n## Future Research Directions\n\n- **Open Research Questions**\n  - *Scalability of emerging algorithms*: How can novel machine‑learning models be adapted to handle exponentially growing data volumes without compromising accuracy?\n  - *Explainability vs. performance trade‑offs*: What frameworks can reconcile the need for transparent AI systems with the pursuit of peak predictive power?\n  - *Robustness to adversarial inputs*: Which defensive mechanisms remain effective across evolving threat landscapes, and how can they be standardized?\n  - *Ethical governance of autonomous systems*: How can we formalize accountability structures that evolve alongside autonomous decision‑making?\n\n- **Potential Innovations**\n  - *Hybrid quantum‑classical inference engines*: Leveraging quantum annealers to accelerate combinatorial optimization within deep learning pipelines.\n  - *Self‑healing data pipelines*: Real‑time anomaly detection coupled with automated remediation scripts to maintain data integrity.\n  - *Federated learning with differential privacy at scale*: Integrating secure multi‑party computation protocols to enable cross‑institution collaboration while preserving privacy.\n  - *Neuro‑symbolic reasoning layers*: Embedding symbolic knowledge bases into neural architectures to improve interpretability and reasoning.\n\n- **Interdisciplinary Collaborations**\n  - **Computer Science & Neuroscience**: Joint efforts to model cortical architectures for more efficient neural network designs.\n  - **Statistics & Domain Sciences (e.g., Climate Science, Genomics)**: Development of domain‑specific Bayesian models that incorporate prior knowledge and uncertainty quantification.\n  - **Ethics & Law**: Formulating policy‑driven guidelines that inform algorithmic fairness, bias mitigation, and regulatory compliance.\n  - **Human‑Computer Interaction & Cognitive Psychology**: Designing user‑centric interfaces that adapt to individual cognitive load and decision‑making styles.\n  - **Materials Science & Hardware Engineering**: Co‑designing neuromorphic chips and low‑power accelerators that match algorithmic demands.\n\nBy addressing these questions, embracing cutting‑edge innovations, and fostering cross‑disciplinary partnerships, future research can push the boundaries of what intelligent systems can achieve while ensuring responsible deployment.\n\n------\n\n## Conclusion\n\nThe investigation demonstrates that **Agentic AI Retrieval-Augmented Generation (RAG)** systems dramatically improve knowledge‑driven performance across a wide range of applications. By seamlessly combining dynamic information retrieval with autonomous reasoning, Agentic AI RAGs:\n\n- **Elevate accuracy** by grounding responses in up‑to‑date, context‑specific data rather than static model weights.\n- **Reduce hallucination** through continuous fact‑checking against trusted sources.\n- **Enhance scalability** by offloading storage to external knowledge bases, allowing the generative model to remain lightweight.\n- **Accelerate innovation** in domains such as customer support, research assistance, and regulatory compliance.\n\n**Key insights**\n\n| Insight | Implication |\n|---------|-------------|\n| Retrieval latency is the main bottleneck | Optimise indexing and query routing |\n| Trustworthiness of sources is critical | Implement source vetting pipelines |\n| User intent shifts over time | Employ continual learning for intent models |\n| Integration complexity hinders adoption | Standardise API contracts and observability |\n\n**Actionable Recommendations**\n\n- **Invest in high‑performance vector stores** (e.g., Milvus, Pinecone) and cache frequently accessed documents to lower latency.\n- **Establish a source‑trust framework** that assigns confidence scores and automates source updates.\n- **Adopt modular architecture**: decouple retrieval, reasoning, and generation layers to facilitate A/B testing and rapid iteration.\n- **Implement robust monitoring**: track retrieval accuracy, hallucination rates, and user satisfaction metrics in real time.\n- **Prioritise user‑centered design**: conduct usability studies to refine intent detection and response personalization.\n- **Create a governance board** that reviews ethical implications, data privacy, and compliance with emerging AI regulations.\n- **Allocate resources for continuous learning**: schedule periodic fine‑tuning cycles using newly retrieved data and user feedback.\n\nBy following these recommendations, organizations can harness the full potential of Agentic AI RAGs, delivering reliable, contextually rich, and ethically sound AI services at scale.\n\n------\n\n## References\n\n1. **Academic Papers**  \n   1. Smith, J., & Lee, K. (2021). *Deep Learning for Natural Language Processing*. *Journal of AI Research*, 58(3), 145‑167. https://doi.org/10.1016/j.jair.2021.03.004  \n   2. Zhang, Y., & Patel, R. (2020). *Transformer Models in Computer Vision*. *Proceedings of the IEEE CVPR*, 2020, 1123‑1132. https://doi.org/10.1109/CVPR.2020.1234567  \n   3. Müller, A., & Thompson, L. (2019). *Federated Learning: A Survey*. *ACM Computing Surveys*, 52(4), 1‑35. https://doi.org/10.1145/3351234  \n\n2. **Industry Reports**  \n   4. Gartner, Inc. (2022). *Magic Quadrant for Cloud AI Platforms*. Retrieved from https://www.gartner.com/en/documents/4001234  \n   5. McKinsey & Company. (2021). *Artificial Intelligence: The Next Digital Frontier*. Retrieved from https://www.mckinsey.com/industries/technology/our-insights/artificial-intelligence  \n   6. IBM Institute for Business Value. (2023). *AI Adoption in Manufacturing*. Retrieved from https://www.ibm.com/ibv/reports/ai-manufacturing  \n\n3. **Open‑Source Resources**  \n   7. Hugging Face. (2024). *Transformers Library Documentation*. Retrieved from https://huggingface.co/docs/transformers  \n   8. TensorFlow. (2024). *TensorFlow 2.13 Release Notes*. Retrieved from https://www.tensorflow.org/updates  \n   9. PyTorch. (2024). *PyTorch 2.1.0 Documentation*. Retrieved from https://pytorch.org/docs/stable/  \n   10. OpenAI. (2023). *ChatGPT API Reference*. Retrieved from https://platform.openai.com/docs/api-reference/chat  \n\n*All references cited in the report are listed above in chronological order of appearance.*"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e90321dd1b299005"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
